Wandb run started
Optimizers Created
Dataloader reset
Beginning Training
====================================================================================================
Model Parameters: 32.1M
{'d_model': 256, 'n_heads': 8, 'n_layers': 8, 'vocab_size': 50304, 'seq_len': 128, 'r': 64, 'p': 2, 'max_steps': 1000000, 'batch_size': 32, 'adam_lr': 0.0003, 'muon_lr': 3e-06}
====================================================================================================
out_proj.weight tensor(0.3035, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(94.8140, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.8000, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.7201, device='cuda:0')
out_proj.weight tensor(0.7466, device='cuda:0')
out_proj.weight tensor(0.8746, device='cuda:0')
out_proj.weight tensor(1.0059, device='cuda:0')
out_proj.weight tensor(1.0722, device='cuda:0')
step 0 | loss 10.8259 | norm 1.2234 | time 1836.4067ms
out_proj.weight tensor(0.3029, device='cuda:0')
out_proj.weight tensor(0.5648, device='cuda:0')
out_proj.weight tensor(0.8568, device='cuda:0')
out_proj.weight tensor(1.1443, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(4.8651, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.6763, device='cuda:0')
out_proj.weight tensor(0.6480, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.1391, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(1.7009, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(0.6579, device='cuda:0')
out_proj.weight tensor(0.6443, device='cuda:0')
out_proj.weight tensor(0.7987, device='cuda:0')
out_proj.weight tensor(0.9198, device='cuda:0')
out_proj.weight tensor(0.9454, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.8081, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(2.2052, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(5.9046, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.0111, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(2.3349, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.0407, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.4018, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(0.4708, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(0.6767, device='cuda:0')
out_proj.weight tensor(0.6585, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(2.0577, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(16.3296, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.6029, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(61.7407, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(6.6668, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(3.3382, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(70.0278, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(21.7772, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.9779, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(8.5221, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(0.6379, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(26.1796, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.2529, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.7997, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.8562, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(12.7122, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(4.9758, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.4121, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(4.5897, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(10.2407, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.9655, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(2.1767, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(1.9717, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(0.8308, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.3345, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.9851, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.0752, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.9534, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(1.0123, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(2.0933, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(8.9703, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(13.4856, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(0.7984, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(3.6835, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.7957, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(3.0004, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(4.8073, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(5.3714, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.2594, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(14.1307, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.9027, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(1.9502, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(1.1028, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.6866, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(2.6186, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(15.4344, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.0066, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.9888, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(0.5273, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(173.9893, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.2772, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(5.4483, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(0.7687, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.5743, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(2.4736, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(39.5651, device='cuda:0')
step 10 | loss 10.7635 | norm 84.0367 | time 1504.5669ms
decoder_stack.0.mlp.l2.weight tensor(3.1237, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(0.6044, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(5.7272, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(121.3122, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(19.7902, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(1.2136, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(3.0273, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(16.6774, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.2785, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(13.7820, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.0254, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(5.7408, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(13.1629, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(5.0499, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(6.9518, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(2.5863, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.3300, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(255.3066, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(4.8506, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(21.6511, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(0.8259, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.9561, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.3749, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(5.9566, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(1.5710, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(5.5889, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(18.2316, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(3.0749, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(3.4044, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(3.0183, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.8516, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(168.3964, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.1470, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(12.8959, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.5996, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.8516, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(40.7416, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.8319, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(63.8107, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.3710, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(110.8094, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.9871, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(0.5716, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(6.7133, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(4.9836, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(5.2979, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(59.5006, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.1962, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.0224, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(1.6109, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(15.2348, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(2.7415, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(5.7176, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1146.3075, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(15.6916, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(5.0897, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(39.6957, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(8.3687, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(19.3204, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.9680, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(19.1243, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(807.8571, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(22.9259, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(8.8099, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(20.8355, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.9563, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(13.5660, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.1306, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(2.1035, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.9023, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(2.1633, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(4.4902, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.9764, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(5.8773, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(3.1141, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(146.2458, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.3766, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(4.3146, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(17.4644, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(19.9699, device='cuda:0')
step 20 | loss 10.6990 | norm 41.2114 | time 1496.8033ms
decoder_stack.0.mlp.l2.weight tensor(20.9397, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(6.8782, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(3.6749, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(22.2036, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(7.2485, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(112.8887, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(35.0203, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(75.3784, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(4.9892, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(3.2104, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(7.2000, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(4.3062, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(7.0026, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(14.7930, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(13.8134, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(42.8834, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.5943, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(3.1074, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(13.5294, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(4.7755, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(34.5390, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(3.8885, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(74.4106, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(3.8693, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(7.8913, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(11.8120, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.3042, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(6.8684, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.6271, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(11.1753, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(8.8669, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(15.5638, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(17.3807, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(8.9019, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(14.9698, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(6.4139, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(28.2913, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(18.1931, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(3.8369, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.3262, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(6.7650, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(3.6895, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(178.3259, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(15.5713, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(11.1505, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(6.9951, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(1204.0229, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(34.4455, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(36.0676, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(24.4216, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(28.8419, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(30.0965, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(6.7565, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(3.6159, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(4.0712, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(3.2182, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(7.4982, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(3.3834, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(32.9165, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(2.5559, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(13.7488, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(53.1976, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(24.9087, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(117.8018, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(61.9963, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(2.9122, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(20.9781, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(3.8755, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(342.6699, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(9.7486, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(2.6987, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(8.5635, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.8285, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(4.0575, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.6483, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.9908, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(4.0786, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.0937, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(29.2416, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(35.4207, device='cuda:0')
step 30 | loss 10.6250 | norm 71.0257 | time 1768.3825ms
decoder_stack.0.attn.wk.weight tensor(0.8560, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(3.3530, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(9.9877, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(4.3200, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(84.0269, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(3.8534, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(7.8683, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(29.0172, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(40.3780, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(1.8387, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(37.6583, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(1.5116, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.3773, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(4.1194, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(7.0650, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(26.0923, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(4.5927, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(94.3816, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(18.6366, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(4.6306, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(3.0336, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(63.2375, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(7.0745, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(766.1023, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(16.4543, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.4403, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(30.0626, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(1.8910, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.4873, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(5.2614, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(3.7596, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(131.4696, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(4.7482, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(7.9077, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(72.0309, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(0.8767, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(5.1700, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(2.5373, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(31.2620, device='cuda:0')
decoder_stack.0.attn.wk.weight tensor(4.0733, device='cuda:0')
decoder_stack.0.attn.wq.weight tensor(6.3565, device='cuda:0')
decoder_stack.0.mlp.l2.weight tensor(4.7842, device='cuda:0')
Traceback (most recent call last):
  File "E:\Other\ATLAS\env\src\linear_transformer.py", line 395, in <module>
    main()
  File "E:\Other\ATLAS\env\src\linear_transformer.py", line 357, in main
    logits = model(xs)
             ^^^^^^^^^
  File "C:\Users\brodi\AppData\Local\Python\pythoncore-3.12-64\Lib\site-packages\torch\nn\modules\module.py", line 1778, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\brodi\AppData\Local\Python\pythoncore-3.12-64\Lib\site-packages\torch\nn\modules\module.py", line 1789, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Other\ATLAS\env\src\linear_transformer.py", line 258, in forward
    x = layer(x)
        ^^^^^^^^
  File "C:\Users\brodi\AppData\Local\Python\pythoncore-3.12-64\Lib\site-packages\torch\nn\modules\module.py", line 1778, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\brodi\AppData\Local\Python\pythoncore-3.12-64\Lib\site-packages\torch\nn\modules\module.py", line 1789, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Other\ATLAS\env\src\linear_transformer.py", line 219, in forward
    x = x + self.attn(norm(x))
            ^^^^^^^^^^^^^^^^^^
  File "C:\Users\brodi\AppData\Local\Python\pythoncore-3.12-64\Lib\site-packages\torch\nn\modules\module.py", line 1778, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\brodi\AppData\Local\Python\pythoncore-3.12-64\Lib\site-packages\torch\nn\modules\module.py", line 1789, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Other\ATLAS\env\src\linear_transformer.py", line 182, in forward
    causal_polysketch_attention(Q, K, V, self.d_key, self.r, self.p)
  File "E:\Other\ATLAS\env\src\linear_transformer.py", line 113, in causal_polysketch_attention
    return D_tilde**-1.0 * fast_lt_mul(phi_Q, phi_K, V)  # (B, H, L, h)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Other\ATLAS\env\src\linear_transformer.py", line 134, in fast_lt_mul
    B[:, :, idx],  # (B, H, b, r^2)
    ~^^^^^^^^^^^
  File "C:\Users\brodi\AppData\Local\Python\pythoncore-3.12-64\Lib\site-packages\torch\utils\_device.py", line 109, in __torch_function__
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
